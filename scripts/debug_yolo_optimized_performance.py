#!/usr/bin/env python3
"""
æœ€é©åŒ–ç‰ˆYOLO TPU ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sys
import os
import time
import numpy as np
import cv2

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.camera import CameraController
from pycoral.utils import edgetpu

def postprocess_yolo_output_optimized(output_data, input_shape, conf_threshold=0.5, iou_threshold=0.45):
    """æœ€é©åŒ–ç‰ˆYOLOå¾Œå‡¦ç†ï¼ˆNumPy vectorizationï¼‰"""
    predictions = output_data[0].transpose()
    h, w = input_shape

    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–: ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    confidences = predictions[:, 4]
    mask = confidences >= conf_threshold

    if not mask.any():
        return []

    filtered_preds = predictions[mask]

    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–: ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹å¤‰æ›
    x_centers = filtered_preds[:, 0]
    y_centers = filtered_preds[:, 1]
    widths = filtered_preds[:, 2]
    heights = filtered_preds[:, 3]
    scores = filtered_preds[:, 4]

    # æ­£è¦åŒ–åº§æ¨™ã«å¤‰æ›
    xmins = np.clip((x_centers - widths / 2) / w, 0, 1)
    ymins = np.clip((y_centers - heights / 2) / h, 0, 1)
    xmaxs = np.clip((x_centers + widths / 2) / w, 0, 1)
    ymaxs = np.clip((y_centers + heights / 2) / h, 0, 1)

    # NMSç”¨ã«å®Ÿåº§æ¨™ã«å¤‰æ›
    boxes_for_nms = np.stack([xmins * w, ymins * h, xmaxs * w, ymaxs * h], axis=1)

    # NMS
    indices = cv2.dnn.NMSBoxes(
        boxes_for_nms.tolist(),
        scores.tolist(),
        conf_threshold,
        iou_threshold
    )

    detections = []
    if len(indices) > 0:
        for i in indices.flatten():
            detections.append({
                'class': 0,
                'score': float(scores[i]),
                'bbox': [float(xmins[i]), float(ymins[i]), float(xmaxs[i]), float(ymaxs[i])]
            })

    return detections


if __name__ == '__main__':
    print("=" * 70)
    print("ğŸš€ æœ€é©åŒ–ç‰ˆYOLO TPU ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    model_path = "models/best_full_integer_quant_edgetpu.tflite"
    print(f"\nğŸ“¦ TPUãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {model_path}")

    interpreter = edgetpu.make_interpreter(model_path)
    interpreter.allocate_tensors()
    print("âœ… Edge TPU ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

    print("\nğŸ“· ã‚«ãƒ¡ãƒ©ã‚’åˆæœŸåŒ–ä¸­...")
    camera = CameraController(resolution=(640, 480), framerate=30, debug=False)

    if not camera.initialize():
        print("âŒ ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ã«å¤±æ•—")
        sys.exit(1)

    if not camera.start():
        print("âŒ ã‚«ãƒ¡ãƒ©ã®èµ·å‹•ã«å¤±æ•—")
        camera.cleanup()
        sys.exit(1)

    time.sleep(2)
    print("âœ… ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–å®Œäº†\n")

    input_details = interpreter.get_input_details()[0]
    output_details = interpreter.get_output_details()[0]
    input_shape = input_details['shape'][1:3]

    input_scale = input_details['quantization'][0]
    input_zero_point = input_details['quantization'][1]
    output_scale = output_details['quantization'][0]
    output_zero_point = output_details['quantization'][1]

    print(f"å…¥åŠ›ã‚µã‚¤ã‚º: {input_shape}\n")

    print("=" * 70)
    print("â±ï¸  100ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‡¦ç†æ™‚é–“ã‚’è¨ˆæ¸¬ä¸­...")
    print("=" * 70)

    total_times = {
        'capture': [],
        'resize': [],
        'quantize': [],
        'inference': [],
        'dequantize': [],
        'postprocess': [],
        'total': []
    }

    num_frames = 100

    for i in range(num_frames):
        frame_start = time.time()

        t1 = time.time()
        frame = camera.capture_frame()
        if frame is None:
            continue
        capture_time = (time.time() - t1) * 1000

        t2 = time.time()
        resized = cv2.resize(frame, (input_shape[1], input_shape[0]))
        resize_time = (time.time() - t2) * 1000

        t3 = time.time()
        input_data = (resized.astype(np.float32) / input_scale + input_zero_point).astype(np.int8)
        input_data = np.expand_dims(input_data, axis=0)
        quantize_time = (time.time() - t3) * 1000

        t4 = time.time()
        interpreter.set_tensor(input_details['index'], input_data)
        interpreter.invoke()
        inference_time = (time.time() - t4) * 1000

        t5 = time.time()
        output_data = interpreter.get_tensor(output_details['index'])
        output_data = (output_data.astype(np.float32) - output_zero_point) * output_scale
        dequantize_time = (time.time() - t5) * 1000

        t6 = time.time()
        detections = postprocess_yolo_output_optimized(
            output_data,
            input_shape=(input_shape[0], input_shape[1]),
            conf_threshold=0.5,
            iou_threshold=0.45
        )
        postprocess_time = (time.time() - t6) * 1000

        total_time = (time.time() - frame_start) * 1000

        total_times['capture'].append(capture_time)
        total_times['resize'].append(resize_time)
        total_times['quantize'].append(quantize_time)
        total_times['inference'].append(inference_time)
        total_times['dequantize'].append(dequantize_time)
        total_times['postprocess'].append(postprocess_time)
        total_times['total'].append(total_time)

        if (i + 1) % 20 == 0:
            print(f"  é€²æ—: {i+1}/{num_frames} ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†å®Œäº†")

    print("\n" + "=" * 70)
    print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆï¼ˆå˜ä½: msï¼‰")
    print("=" * 70)

    for key, times in total_times.items():
        avg = np.mean(times)
        std = np.std(times)
        min_t = np.min(times)
        max_t = np.max(times)

        label = {
            'capture': '1. ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—',
            'resize': '2. ãƒªã‚µã‚¤ã‚º',
            'quantize': '3. é‡å­åŒ–',
            'inference': '4. TPUæ¨è«–',
            'dequantize': '5. é€†é‡å­åŒ–',
            'postprocess': '6. YOLOå¾Œå‡¦ç†(æœ€é©åŒ–)',
            'total': 'ã€åˆè¨ˆã€‘'
        }[key]

        print(f"\n{label}:")
        print(f"  å¹³å‡: {avg:6.2f} ms")
        print(f"  æ¨™æº–åå·®: {std:6.2f} ms")
        print(f"  æœ€å°: {min_t:6.2f} ms")
        print(f"  æœ€å¤§: {max_t:6.2f} ms")

    avg_total = np.mean(total_times['total'])
    theoretical_fps = 1000.0 / avg_total

    print("\n" + "=" * 70)
    print(f"ğŸ¯ ç†è«–ä¸Šã®FPS: {theoretical_fps:.1f}")
    print("=" * 70)

    print("\nğŸ“ˆ å‡¦ç†æ™‚é–“ã®å†…è¨³:")
    total_avg = np.mean(total_times['total'])
    for key in ['capture', 'resize', 'quantize', 'inference', 'dequantize', 'postprocess']:
        avg = np.mean(total_times[key])
        percentage = (avg / total_avg) * 100
        label = {
            'capture': 'ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—',
            'resize': 'ãƒªã‚µã‚¤ã‚º',
            'quantize': 'é‡å­åŒ–',
            'inference': 'TPUæ¨è«–',
            'dequantize': 'é€†é‡å­åŒ–',
            'postprocess': 'YOLOå¾Œå‡¦ç†'
        }[key]
        print(f"  {label:15s}: {avg:6.2f} ms ({percentage:5.1f}%)")

    print("\n" + "=" * 70)
    print("ğŸ”¥ æœ€é©åŒ–çµæœã®æ¯”è¼ƒ:")
    print(f"  å…ƒã®å¾Œå‡¦ç†æ™‚é–“: 104.60 ms")
    print(f"  æœ€é©åŒ–å¾Œå‡¦ç†æ™‚é–“: {np.mean(total_times['postprocess']):.2f} ms")
    improvement = ((104.60 - np.mean(total_times['postprocess'])) / 104.60) * 100
    print(f"  æ”¹å–„ç‡: {improvement:.1f}%")
    print("=" * 70)

    camera.stop()
    camera.cleanup()
    print("\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
